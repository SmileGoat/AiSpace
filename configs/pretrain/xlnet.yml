# config for xlnet chinese
includes:
  - ../base.yml

dataset:
    tokenizer:
        name: bert_tokenizer
        vocab:
            filename: null
            special_tokens:
                PAD: [PAD]
                UNK: [UNK]
                SEP: [SEP]
                CLS: [CLS]
                MASK: [MASK]
        tokenize_chinese_chars: True
        do_lower_case: True
        do_basic_tokenize: True
        non_split_tokens: null
        max_len: null

pretrained:
    norm_name: xlnet
    name: xlnet-base-cased
    adapter: tf_huggingface_bert_adapter
    force_download: false
    init_from_pretrained: true
    cache_dir: /search/data1/yyk/data/pretrained/xlnet   # your path to save models
    model_path: null
    vocab_path: null
    config_path: null
    config:
       output_attentions: false
       output_hidden_states: false
       layer_norm_eps: 1e-12
       hidden_size: 1024

    ref: https://github.com/ymcui/Chinese-BERT-wwm
    family:
        xlnet-base-cased:
            model:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-tf_model.h5
                to_insert_paths:
                    - pretrained.model_path
            vocab:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model
                to_insert_paths:
                    - pretrained.vocab_path
                    - dataset.tokenizer.vocab.filename
            config:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json
                to_insert_paths: # set the pretrained.config_path with saved path of this file.
                    - pretrained.config_path
                to_replaces: # replace pretrained.config with the json content.
                    - pretrained.config
        xlnet-large-cased:
            model:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-large-cased-tf_model.h5
                to_insert_paths:
                    - pretrained.model_path
            vocab:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-large-cased-spiece.model
                to_insert_paths:
                    - pretrained.vocab_path
                    - dataset.tokenizer.vocab.filename
            config:
                url: https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-large-cased-config.json
                to_insert_paths: # set the pretrained.config_path with saved path of this file.
                    - pretrained.config_path
                to_replaces: # replace pretrained.config with the json content.
                    - pretrained.config

