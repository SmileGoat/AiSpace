includes:
  - "../pretrain/bert_huggingface.yml"

model_name: bert_for_classification

model_attributes:
    hidden_dropout_prob: 0.5
    initializer_range: 0.02
    hidden_size: 1024

training:
  learning_rate: 3e-5
  max_epochs: 30
  batch_size: 32
  callbacks:
    # callback name
    early_stopping:
      switch: true

dataset:
  name: glue_zh/tnews
  data_dir: "./data"
  transformer: "glue_zh/tnews"

  source:
    train: "train[:80%]"
    validation: "train[-20%:]"
    test: "validation"

  tokenizer:
    max_len: 100

  inputs:
    - name: input_ids
      column: input_ids
      type: LIST_OF_INT
      max_len: 100
    - name: token_type_ids
      column: token_type_ids
      type: LIST_OF_INT
      max_len: 100
    - name: attention_mask
      column: attention_mask
      type: LIST_OF_INT
      max_len: 100

  outputs:
    - name: output_1
      column: label
      type: CLASSLABEL
      num: 15
      labels: ["news_story", "news_culture", "news_entertainment", "news_sports", "news_finance",
               "news_house", "news_car", "news_edu", "news_tech", "news_military", "news_travel",
               "news_world", "news_stock", "news_agriculture", "news_game"]
      loss:
        name: sparse_categorical_crossentropy
        config:
          from_logits: true
      metrics:
        - name: sparse_categorical_accuracy

pretrained:
    name: bert-base-chinese-huggingface
    init_from_pretrained: true


