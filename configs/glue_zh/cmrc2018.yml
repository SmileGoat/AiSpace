includes:
#  - "../base.yml"
  - "../pretrain/bert_huggingface.yml"
#  - "../pretrain/nezha.yml"
#  - "../pretrain/electra_chinese.yml"
#  - "../pretrain/ernie.yml"
#  - "../pretrain/xlnet_chinese.yml"

model_name: bert_for_qa

model_attributes:
    hidden_dropout_prob: 0.5
    initializer_range: 0.02
    hidden_size: 798
    start_n_top: 5
    layer_norm_eps: 1e-12
    qa_layer_name: "qa_with_impossible"

training:
#  policy:
#    name: "k-fold"
#    config:
#      k: 5
  learning_rate: 3e-5
  max_epochs: 10
  batch_size: 24
#  steps_per_epoch: 10
  do_eval: false       # using callback doing evaluation instead of default eval because of different outputs of training stages.
#  validation_steps: 10

  callbacks:
    # callback name
    early_stopping:
      switch: False
      config:
        monitor: "val_f1_em_avg_score"
        mode: "max"
        patience: 2
    evaluator_for_qa_with_impossible:
      switch: True
      config:
        validation_dataset: null
        validation_steps: null

  optimizer_wrappers:
    swa:
      switch: false
      config:
        start_epoch: 5
    lr_multiplier:
      switch: True
      config:
        multipliers:
          bert_for_qa/bert: 0.01

dataset:
  name: glue_zh/cmrc2018
  data_dir: "./data"
  transformer: "glue_zh/cmrc2018"

  source:
    train: "train"
    validation: 'validation'
    test: "validation"

  tokenizer:
    max_query_length: 64
    max_answer_length: 64
    doc_stride: 128

  inputs:
    - name: unique_id
      column: unique_id
      type: INT
      model_input: True
    - name: qas_id
      column: qas_id
      type: STRING
      model_input: False
    - name: question_text
      column: question_text
      type: STRING
      model_input: False
    - name: context_text
      column: context_text
      type: STRING
      model_input: False
    - name: answer_text
      column: answer_text
      type: STRING
      model_input: False
    - name: answer_text
      column: all_answers
      type: STRING
      model_input: False
    - name: doc_token2char_raw_start_index
      column: doc_token2char_raw_start_index
      type: STRING
      model_input: False
    - name: doc_token2char_raw_end_index
      column: doc_token2char_raw_end_index
      type: STRING
      model_input: False
    - name: doc_token2doc_index
      column: doc_token2doc_index
      type: STRING
      model_input: False
    - name: offset
      column: offset
      type: INT
      model_input: False
    - name: input_ids
      column: input_ids
      type: LIST_OF_INT
      max_len: 512
    - name: token_type_ids
      column: token_type_ids
      type: LIST_OF_INT
      max_len: 512
    - name: attention_mask
      column: attention_mask
      type: LIST_OF_INT
      max_len: 512
    - name: p_mask
      column: p_mask
      type: LIST_OF_INT
      max_len: 512
    - name: start_position
      column: start_position
      type: CLASSLABEL
      num: 512
      labels: use_num

  outputs:
    - name: output_1
      column: start_position
      type: CLASSLABEL
      num: 512
      labels: use_num
      weight: 0.5
      loss:
        name: sparse_categorical_crossentropy
        config:
          from_logits: True
      metrics:
        - name: sparse_recall
          config:
            name: "macro_recall"
            num_classes: 512
            average: "macro"
#        - name: sparse_categorical_accuracy
#        - name: sparse_f1_score
#          config:
#            name: "macro_f1"
#            num_classes: 512
#            average: "macro"
    - name: output_2
      column: end_position
      type: CLASSLABEL
      num: 512
      labels: use_num
      weight: 0.5
      loss:
        name: sparse_categorical_crossentropy
        config:
          from_logits: True
      metrics:
        - name: sparse_recall
          config:
            name: "macro_recall"
            num_classes: 512
            average: "macro"
#        - name: sparse_categorical_accuracy
#        - name: sparse_f1_score
#          config:
#            name: "macro_f1"
#            num_classes: 512
#            average: "macro"
    - name: output_3
      column: is_impossible
      type: INT
      weight: 1.0
      loss:
        name: sigmoid_cross_entropy
      metrics:
        - name: binary_accuracy

pretrained:
#    name: ERNIE_1.0_max-len-512
#    name: chinese_xlnet_mid
#    name: chinese_electra_base
#    name: NEZHA-Base
    name: bert-base-chinese-huggingface
    init_from_pretrained: false
#    config:
#      use_task_id: false


